{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stock Market Prediction</h1>\n",
    "After Stock market analysis, lets start with stock market prediction.\n",
    "For Stock market Prediction we will be using different algorithms and models. In this notebook we will be trying to fit our data in different models.\n",
    "Various models, toolkits and algorithms used in this notebook are K-Nearest Neighbours, FBProphet, Auto-Arima and LSTM.\n",
    "In this Notebook we will be trying to predict the stock prices in upcoming days and a indicator that will show us on which days the stock prices will go up or down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuvraj/.local/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:\n",
      "\n",
      "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/pyramid/__init__.py:68: UserWarning:\n",
      "\n",
      "\n",
      "    The 'pyramid' package will be migrating to a new namespace beginning in \n",
      "    version 1.0.0: 'pmdarima'. This is due to a package name collision with the\n",
      "    Pyramid web framework. For more information, see Issue #34:\n",
      "    \n",
      "        https://github.com/tgsmith61591/pyramid/issues/34\n",
      "        \n",
      "    The package will subsequently be installable via the name 'pmdarima'; the\n",
      "    only functional change to the user will be the import name. All imports\n",
      "    from 'pyramid' will change to 'pmdarima'.\n",
      "    \n",
      "\n",
      "Using TensorFlow backend.\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/yuvraj/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for k-nearest neighbours\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from stocker import Stocker #for stocker toolkit\n",
    "\n",
    "from pyramid.arima import auto_arima #for ARIMA\n",
    "\n",
    "#for LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#for importing stock data files\n",
    "import file_import\n",
    "#for Dataframe\n",
    "import pandas as pd\n",
    "#for Date and Time objects\n",
    "import datetime\n",
    "#for spliting the data into testing and training dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Matplotlib for ploting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import call_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with importing stock data into a Pandas Dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets us see the first 10 rows of the wmt stock\n",
      "\n",
      "                  Open       High        Low      Close      Volume  OpenInt\n",
      "Date                                                                       \n",
      "1972-03-20    0.03403    0.03403    0.03403    0.03403   3132119.0      0.0\n",
      "1972-03-22    0.03403    0.04251    0.03403    0.03403   1084194.0      0.0\n",
      "1972-03-23    0.03403    0.04251    0.03403    0.03403    783030.0      0.0\n",
      "1972-03-24    0.03403    0.04251    0.03403    0.03403   1264892.0      0.0\n",
      "1972-03-27    0.04251    0.04251    0.04251    0.04251   1385361.0      0.0\n",
      "...               ...        ...        ...        ...         ...      ...\n",
      "2019-11-14  124.60000  125.38000  119.51000  120.65000  22504200.0      NaN\n",
      "2019-11-15  120.68000  121.00000  118.38000  118.87000   9531474.0      NaN\n",
      "2019-11-18  118.45000  120.86700  118.24000  120.36500   2116593.0      NaN\n",
      "2019-11-19  120.11000  120.36000  119.71000  119.89000   3715400.0      NaN\n",
      "2019-11-20  120.21000  120.48000  119.38000  119.55000   1281753.0      NaN\n",
      "\n",
      "[11952 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data, lis, file_name = file_import.operate_file() #Here data holds the stock data\n",
    "#up_data = call_api.data_update(data, file_name, lis[0])\n",
    "#data = pd.concat([data, up_data], sort = True)\n",
    "stock_name = lis[0]\n",
    "start_date = lis[1]\n",
    "end_date = lis[2]\n",
    "#data = data.drop(['1. open','2. high','3. low','4. close','5. volume','OpenInt'], axis = 1)\n",
    "print(\"Lets us see the first 10 rows of the %s stock\\n\\n\"%(stock_name),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates( keep = False, inplace = True) \n",
    "x = 0\n",
    "while(x == 0):\n",
    "    y,m,d = start_date.split('-',3)\n",
    "    temp_date = datetime.date(int(y),int(m),int(d))\n",
    "    \n",
    "    df = data.loc[start_date : end_date, : ] #Slicing the data from start date to end date\n",
    "    if(len(df.index) == 0):\n",
    "        print(\"Date Interval specified is Invalid \\nPlease, Re-Enter the date in Valid format YYYY-MM-DD : \\n\")\n",
    "        continue\n",
    "    x = 1\n",
    "\n",
    "df.index = pd.to_datetime(df.index) #Converting index to datetime object so that daily, monthly or yearly data could be taken out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (indexers.py, line 22)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/yuvraj/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d671c956cbe6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import indexers\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/yuvraj/PycharmProjects/SMAP/notebooks/indexers.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    for name,indexer in final_indexers.items():\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import indexers\n",
    "indexer = indexers()\n",
    "df = indexer.operate_file(df, str(start_date), str(end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing stock data file into a DataFrame object let us split that data into training and testing dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = df.shape\n",
    "x = int(li[0] - 0.2*li[0])\n",
    "train = df[ : x]\n",
    "valid = df[x : ]\n",
    "x_train = train.drop('Close', axis=1)\n",
    "y_train = train['Close']\n",
    "x_valid = valid.drop('Close', axis=1)\n",
    "y_valid = valid['Close']\n",
    "len_valid = valid.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, Let us now apply machine learning algorithms and model.\n",
    "<h2>K-Nearest Neighbours</h2>\n",
    "One of the most interesting ML algorithm that one can use here is kNN (k nearest neighbours). Based on the independent variables, kNN finds the similarity between new data points and old data points.\n",
    "<h3>Pseudo Code of KNN</h3>\n",
    "We can implement a KNN model by following the below steps:\n",
    "<ol>\n",
    "    <li>Load the data</li>\n",
    "    <li>Initialise the value of k</li>\n",
    "    <li>For getting the predicted class, iterate from 1 to total number of training data points</li><ol>\n",
    "        <li>Calculate the distance between test data and each row of training data. Here we will use Euclidean distance as our distance metric since it’s the most popular method. The other metrics that can be used are Chebyshev, cosine, etc.</li>\n",
    "        <li>Sort the calculated distances in ascending order based on distance values</li>\n",
    "        <li>Get top k rows from the sorted array</li>\n",
    "        <li>Get the most frequent class of these rows</li>\n",
    "        <li>Return the predicted class</li></ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaling data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_valid = pd.DataFrame(x_valid_scaled)\n",
    "\n",
    "#using gridsearch to find the best parameter\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "\n",
    "#fit the model and make predictions\n",
    "model.fit(x_train,y_train)\n",
    "preds = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "print(str(rms) + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if('Prediction' in valid.columns):\n",
    "    valid.drop('Prediction', axis = 1)\n",
    "    \n",
    "#ploting using matplotlib\n",
    "valid['Predictions'] = preds\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "plt.xlabel('Time---->')\n",
    "plt.ylabel('Price in Dollars----->')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "print(str(rms) + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_scaling\n",
    "valid = simple_scaling.simple(data = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions','New Predictions']])\n",
    "plt.xlabel('Time---->')\n",
    "plt.ylabel('Price in Dollars----->')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(valid['Close'])-np.array(valid['New Predictions'])),2)))\n",
    "print(str(rms) + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_new = simple_scaling.additive(valid)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid_new[['Close','Predictions','New Prediction']])\n",
    "plt.xlabel('Time---->')\n",
    "plt.ylabel('Price in Dollars----->')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(valid_new[\"Close\"])-np.array(valid_new[\"New Prediction\"])),2)))\n",
    "print(str(rms) + \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auto ARIMA</h2>\n",
    "Introduction\n",
    "\n",
    "ARIMA is a very popular statistical method for time series forecasting. ARIMA models take into account the past values to predict the future values. There are three important parameters in ARIMA:\n",
    "\n",
    "    p (past values used for forecasting the next value)\n",
    "    q (past forecast errors used to predict the future values)\n",
    "    d (order of differencing)\n",
    "\n",
    "Parameter tuning for ARIMA consumes a lot of time. So we will use auto ARIMA which automatically selects the best combination of (p,q,d) that provides the least error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train['Close']\n",
    "validation = valid['Close']\n",
    "\n",
    "model = auto_arima(training, start_p=1, start_q=1,max_p=3, max_q=3, m=12,start_P=0, seasonal=True,d=1, D=1, trace=True,error_action='ignore',suppress_warnings=True)\n",
    "model.fit(training)\n",
    "\n",
    "forecast = model.predict(n_periods=len_valid)\n",
    "forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(valid['Close'])-np.array(forecast['Prediction'])),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid['Close'])\n",
    "plt.plot(forecast['Prediction'])\n",
    "plt.xlabel('Time---->')\n",
    "plt.ylabel('Price in Dollars----->')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Long Short Term Memory (LSTM)</h2>\n",
    "\n",
    "LSTMs are widely used for sequence prediction problems and have proven to be extremely effective. The reason they work so well is because LSTM is able to store past information that is important, and forget the information that is not. LSTM has three gates:\n",
    "\n",
    "    The input gate: The input gate adds information to the cell state\n",
    "    The forget gate: It removes the information that is no longer required by the model\n",
    "    The output gate: Output Gate at LSTM selects the information to be shown as output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "df = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(df)):\n",
    "    new_data['Date'][i] = df.index[i]\n",
    "    new_data['Close'][i] = df['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "li = dataset.shape\n",
    "x = int(li[0] - 0.2*li[0])\n",
    "train = dataset[ : x]\n",
    "valid = dataset[x : ]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=3, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = new_data.shape\n",
    "x = int(li[0] - 0.2*li[0])\n",
    "train = new_data[ : x]\n",
    "valid = new_data[x : ]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "df = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(df)):\n",
    "    new_data['Date'][i] = df.index[i]\n",
    "    new_data['Close'][i] = df['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "li = dataset.shape\n",
    "x = int(li[0] - 0.2*li[0])\n",
    "train = dataset[ : x]\n",
    "valid = dataset[x : ]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=4, verbose=4)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = new_data.shape\n",
    "x = int(li[0] - 0.2*li[0])\n",
    "train = new_data[ : x]\n",
    "valid = new_data[x : ]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Begin with Stocker</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = Stocker(stock_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.plot_stock(stats=['Daily Change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_data = stock.create_prophet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(model_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_data = stock.create_prophet_model(days=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.evaluate_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
