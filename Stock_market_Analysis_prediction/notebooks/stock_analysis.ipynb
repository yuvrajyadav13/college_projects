{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Analysis\n",
    "In this report we will analyze the stock data. And derive insights from it.\n",
    "Firstly, we will be cleaning checking if there are any null values or outliers in the data and then clean the data. Then we will be performing real time data analysis that is how the stocks are working with help of several strategies like, stock return, moving average, etc,.\n",
    "So, lets begin by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.024Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  #for plotting the graphs\n",
    "import numpy as np               #for operting on arrays if needed               #for importing the Stock data file\n",
    "import datetime       #for taking date object\n",
    "import pandas as pd\n",
    "import file_import\n",
    "import call_api\n",
    "from stocker import Stocker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing important files. Let us load data of a particular stock into the pandas dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.038Z"
    }
   },
   "outputs": [],
   "source": [
    "data, lis, file_name = file_import.operate_file() #Here data holds the stock data\n",
    "up_data = call_api.data_update(data, file_name, lis[0])\n",
    "data = pd.concat([data, up_data], sort = True)\n",
    "stock_name = lis[0]\n",
    "start_date = lis[1]\n",
    "end_date = lis[2]\n",
    "data = data.drop(['1. open','2. high','3. low','4. close','5. volume'], axis = 1)\n",
    "print(\"Lets us see the first 10 rows of the %s stock\\n\\n\"%(stock_name),data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the interval from which the user wants to analyze the data.(In terms of date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.054Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates( keep = False, inplace = True) \n",
    "x = 0\n",
    "while(x == 0):\n",
    "    y,m,d = start_date.split('-',3)\n",
    "    temp_date = datetime.date(int(y),int(m),int(d))\n",
    "    \n",
    "    df = data.loc[start_date : end_date, : ] #Slicing the data from start date to end date\n",
    "    if(len(df.index) == 0):\n",
    "        print(\"Date Interval specified is Invalid \\nPlease, Re-Enter the date in Valid format YYYY-MM-DD : \\n\")\n",
    "        continue\n",
    "    x = 1\n",
    "\n",
    "df.index = pd.to_datetime(df.index) #Converting index to datetime object so that daily, monthly or yearly data could be taken out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Describing Selected Data</h2>\n",
    "After selecting the stock data let us describe it. Describe is a inbuilt function in python that is used for describing the data. Describe function returns a table which contain mean, standard deviation, minimum values, etc,. All the values that describe function gives are:\n",
    "<ul>\n",
    "   <li>count = Number of elements in that column</li>\n",
    "   <li>mean = Arithematic mean of the elements in that column</li>\n",
    "   <li>std = Standard Deviation</li>\n",
    "   <li>min = Minumum value in that column</li>\n",
    "   <li>25% = Gives highest value in lower 25% values</li>\n",
    "   <li>50% = Gives highest values in lower 50% values</li>\n",
    "   <li>75% = Gives highest values in lower 75% values</li>\n",
    "   <li>max = Maximum value in that column</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.065Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Simple Line Graph</h2>\n",
    "Graphs and Charts are one of the best ways of representing a data. They provide much better insights on how any data is moving. Simple line graph of Open, High, Low and Close values of the stocks. Simple line graph doesn't provide much details. But for getting started with visualizing the stock data lets plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.074Z"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "pt = df[[\"Open\",\"Close\",\"High\",\"Low\"]].plot(grid = True)\n",
    "pt.set_xlabel(\"Year\")\n",
    "pt.set_ylabel(\"Price\")\n",
    "savefig('graph.png')\n",
    "plt.show()\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Discovering the Relation between Total Traded Quantity vs Close Price</h2>\n",
    "Usually, traded quantity increases if the stock price increases or decreases too rapidly on a given day. This parameter is important for our model for prediction. So we should take some time out to identify the relation between them in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.082Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n",
    "\n",
    "(ggplot(df, aes('Close', 'Volume', colour = 'Close'))\n",
    " + geom_point()\n",
    " + stat_smooth(method='loess')\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stock's Return</h2>\n",
    "A “better” solution, though, would be to plot the information we actually want: the stock’s returns. This involves transforming the data into something more useful for our purposes. There are multiple transformations we could apply.\n",
    "\n",
    "One transformation would be to consider the stock’s return since the beginning of the period of interest. In other words, we plot:\n",
    "\n",
    "$\\text{return}_{t,0} = \\frac{\\text{price}_t}{\\text{price}_0}$\n",
    "\n",
    "This will require transforming the data in the stocks object, which I do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.090Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_return = df[\"Close\"].apply(lambda x: x / df.Close[0])\n",
    "stock_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.097Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_return.plot(grid = True).axhline(y = 1, color = \"black\", lw = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logarithmic Stock Change</h2>\n",
    "Logarithmic Stock change can describe volatility of any share in the best way. Here, $\\log$ is the natural log, and our definition does not depend as strongly on whether we use<br> \n",
    "$\\log(\\text{price}_{t}) - \\log(\\text{price}_{t - 1})$<br>\n",
    "                          or <br>\n",
    "$\\log(\\text{price}_{t+1}) - \\log(\\text{price}_{t}).)$<br> \n",
    "The advantage of using log differences is that this difference can be interpreted as the percentage change in a stock but does not depend on the denominator of a fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.104Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_change = df.Close.diff() #Diff()\n",
    "stock_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.110Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_change.plot(grid = True).axhline(y = 0, color = \"black\", lw = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Japanese Candlestick Plot</h2>\n",
    "\n",
    "A linechart is fine, but there are at least four variables involved for each date (open, high, low, and close), and we would like to have some visual way to see all four variables that does not require plotting four separate lines. Financial data is often plotted with a Japanese candlestick plot, so named because it was first created by 18th century Japanese rice traders. Such a chart can be created with matplotlib, though it requires considerable effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.118Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, WeekdayLocator,\\\n",
    "    DayLocator, MONDAY\n",
    "from mpl_finance import candlestick_ohlc\n",
    " \n",
    "def pandas_candlestick_ohlc(dat, stick = \"day\", otherseries = None):\n",
    "    #dat: pandas DataFrame object with datetime64 index, and float columns \"Open\", \"High\", \"Low\", and \"Close\", likely created via DataReader from \"yahoo\"\n",
    "    #stick: A string or number indicating the period of time covered by a single candlestick. Valid string inputs include \"day\", \"week\", \"month\", and \"year\", (\"day\" default), and any numeric input indicates the number of trading days included in a period\n",
    "    #otherseries: An iterable that will be coerced into a list, containing the columns of dat that hold other series to be plotted as lines\n",
    "    #This will show a Japanese candlestick plot for stock data stored in dat, also plotting other series if passed.\n",
    "    mondays = WeekdayLocator(MONDAY)        # major ticks on the mondays\n",
    "    alldays = DayLocator()              # minor ticks on the days\n",
    "    dayFormatter = DateFormatter('%d')      # e.g., 12\n",
    " \n",
    "    # Create a new DataFrame which includes OHLC data for each period specified by stick input\n",
    "    transdat = dat.loc[:,[\"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "    if (type(stick) == str):\n",
    "        if stick == \"day\":\n",
    "            plotdat = transdat\n",
    "            stick = 1 # Used for plotting\n",
    "        elif stick in [\"week\", \"month\", \"year\"]:\n",
    "            if stick == \"week\":\n",
    "                transdat[\"week\"] = pd.to_datetime(transdat.index).map(lambda x: x.isocalendar()[1]) # Identify weeks\n",
    "            elif stick == \"month\":\n",
    "                transdat[\"month\"] = pd.to_datetime(transdat.index).map(lambda x: x.month) # Identify months\n",
    "            transdat[\"year\"] = pd.to_datetime(transdat.index).map(lambda x: x.isocalendar()[0]) # Identify years\n",
    "            grouped = transdat.groupby(list(set([\"year\",stick]))) # Group by year and other appropriate variable\n",
    "            plotdat = pd.DataFrame({\"Open\": [], \"High\": [], \"Low\": [], \"Close\": []}) # Create empty data frame containing what will be plotted\n",
    "            for name, group in grouped:\n",
    "                plotdat = plotdat.append(pd.DataFrame({\"Open\": group.iloc[0,0],\n",
    "                                            \"High\": max(group.High),\n",
    "                                            \"Low\": min(group.Low),\n",
    "                                            \"Close\": group.iloc[-1,3]},\n",
    "                                           index = [group.index[0]]))\n",
    "            if stick == \"week\": stick = 5\n",
    "            elif stick == \"month\": stick = 30\n",
    "            elif stick == \"year\": stick = 365\n",
    " \n",
    "    elif (type(stick) == int and stick >= 1):\n",
    "        transdat[\"stick\"] = [np.floor(i / stick) for i in range(len(transdat.index))]\n",
    "        grouped = transdat.groupby(\"stick\")\n",
    "        plotdat = pd.DataFrame({\"Open\": [], \"High\": [], \"Low\": [], \"Close\": []}) # Create empty data frame containing what will be plotted\n",
    "        for name, group in grouped:\n",
    "            plotdat = plotdat.append(pd.DataFrame({\"Open\": group.iloc[0,0],\n",
    "                                        \"High\": max(group.High),\n",
    "                                        \"Low\": min(group.Low),\n",
    "                                        \"Close\": group.iloc[-1,3]},\n",
    "                                       index = [group.index[0]]))\n",
    " \n",
    "    else:\n",
    "        raise ValueError('Valid inputs to argument \"stick\" include the strings \"day\", \"week\", \"month\", \"year\", or a positive integer')\n",
    " \n",
    " \n",
    "    # Set plot parameters, including the axis object ax used for plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    if (plotdat.index[-1] - plotdat.index[0] < pd.Timedelta('730 days')):\n",
    "        weekFormatter = DateFormatter('%b %d')  # e.g., Jan 12\n",
    "        ax.xaxis.set_major_locator(mondays)\n",
    "        ax.xaxis.set_minor_locator(alldays)\n",
    "    else:\n",
    "        weekFormatter = DateFormatter('%b %d, %Y')\n",
    "    ax.xaxis.set_major_formatter(weekFormatter)\n",
    " \n",
    "    ax.grid(True)\n",
    " \n",
    "    # Create the candelstick chart\n",
    "    candlestick_ohlc(ax, list(zip(list(date2num(plotdat.index.tolist())), plotdat[\"Open\"].tolist(), plotdat[\"High\"].tolist(),\n",
    "                      plotdat[\"Low\"].tolist(), plotdat[\"Close\"].tolist())),\n",
    "                      colorup = \"green\", colordown = \"red\", width = stick * .4)\n",
    " \n",
    "    # Plot other series (such as moving averages) as lines\n",
    "    if otherseries != None:\n",
    "        if type(otherseries) != list:\n",
    "            otherseries = [otherseries]\n",
    "        dat.loc[:,otherseries].plot(ax = ax, lw = 1.3, grid = True)\n",
    " \n",
    "    ax.xaxis_date()\n",
    "    ax.autoscale_view()\n",
    "    plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    plt.show()\n",
    " \n",
    "pandas_candlestick_ohlc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Moving Averages</h2>\n",
    "\n",
    "Charts are very useful. In fact, some traders base their strategies almost entirely off charts (these are the “technicians”, since trading strategies based off finding patterns in charts is a part of the trading doctrine known as technical analysis). Let’s now consider how we can find trends in stocks.\n",
    "\n",
    "A q-day moving average is, for a series x_t and a point in time t, the average of the past $q$ days: that is, if MA^q_t denotes a moving average process, then:\n",
    "\n",
    "$MA^q_t = \\frac{1}{q} \\sum_{i = 0}^{q-1} x_{t - i}$\n",
    "\n",
    "Moving averages smooth a series and helps identify trends. The larger q is, the less responsive a moving average process is to short-term fluctuations in the series x_t. The idea is that moving average processes help identify trends from “noise”. Fast moving averages have smaller q and more closely follow the stock, while slow moving averages have larger q, resulting in them responding less to the fluctuations of the stock and being more stable.\n",
    "\n",
    "pandas provides functionality for easily computing moving averages. I demonstrate its use by creating a 20-day (one month) moving average for the Apple data, and plotting it alongside the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.127Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"20d\"] = np.round(df[\"Close\"].rolling(window = 20, center = False).mean(), 2)\n",
    "x_date = temp_date + datetime.timedelta(days = 20)\n",
    "x_date = str(x_date)\n",
    "pandas_candlestick_ohlc(df.loc[x_date : end_date, : ], otherseries = \"20d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multiple Moving Averages</h2>\n",
    "Traders are usually interested in multiple moving averages, such as the 20-day, 50-day, and 200-day moving averages. It’s easy to examine multiple moving averages at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.135Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"50d\"] = np.round(df[\"Close\"].rolling(window = 50, center = False).mean(), 2)\n",
    "df[\"200d\"] = np.round(df[\"Close\"].rolling(window = 200, center = False).mean(), 2)\n",
    "x_date = temp_date + datetime.timedelta(days = 200)\n",
    "x_date = str(x_date)\n",
    "pandas_candlestick_ohlc(df.loc[x_date : end_date, : ], otherseries = [\"20d\", \"50d\", \"200d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.140Z"
    }
   },
   "outputs": [],
   "source": [
    "stock = Stocker(stock_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.146Z"
    }
   },
   "outputs": [],
   "source": [
    "del df['OpenInt']\n",
    "del df['50d']\n",
    "del df['200d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing Stationarity</h1>\n",
    "Stationarity in any time series helps in checking whether the statistical properties like mean, variance, deviation, etc,. are constant or not. A stationary time series data makes itself easier to analyze and predict the further outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.150Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['RollStd'] = np.round(df[\"Close\"].rolling(window = 20, center = False).std(), 2)\n",
    "new_df = df.dropna( axis = 0)\n",
    "pt = new_df[[\"Close\",\"20d\",'RollStd']].plot(grid = True)\n",
    "pt.set_xlabel(\"Year\")\n",
    "pt.set_ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.155Z"
    }
   },
   "outputs": [],
   "source": [
    "#Performing Dickey-Fuller test:\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "print('Results of Dickey-Fuller Test:')\n",
    "dftest = adfuller(new_df['Close'], autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Open','High',\"Voltality\",'20d'])\n",
    "for key, value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Making data Stationary</h2>\n",
    "Now, let us try to make data stationary by applying various methods\n",
    "<h3>Estimating & Eliminating Trend</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.161Z"
    }
   },
   "outputs": [],
   "source": [
    "df_log = np.log(new_df['Close'])\n",
    "plt.plot(df_log)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Smoothing</h3>\n",
    "Taking Moving averages of log values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.167Z"
    }
   },
   "outputs": [],
   "source": [
    "#moving_avg = pd.rolling_mean(df_log, 10, min_periods=1)\n",
    "moving_avg = np.round(df_log.rolling(window = 10, center = False).mean(), 2)\n",
    "plt.plot(df_log)\n",
    "plt.plot(moving_avg, color='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.171Z"
    }
   },
   "outputs": [],
   "source": [
    "moving_avg_diff = df_log - moving_avg\n",
    "moving_avg_diff.dropna(inplace = True)\n",
    "\n",
    "def test_stats(ts):\n",
    "    rolmean = ts.rolling(window=20, center = False).mean()\n",
    "    rolstd = ts.rolling(window=20, center = False).std()\n",
    "\n",
    "    #plotting\n",
    "    orig = plt.plot(ts, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='green', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "test_stats(moving_avg_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.175Z"
    }
   },
   "outputs": [],
   "source": [
    "def adf(ts):\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(ts, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Open','High',\"Voltality\",'20d'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "adf(moving_avg_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exponentially Weighted Moving Average</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.180Z"
    }
   },
   "outputs": [],
   "source": [
    "expwighted_avg = df_log.ewm(halflife = 12).mean()\n",
    "\n",
    "plt.plot(df_log)\n",
    "plt.plot(expwighted_avg, color='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.185Z"
    }
   },
   "outputs": [],
   "source": [
    "df_log_emw_avg = df_log - expwighted_avg #difference\n",
    "test_stats(df_log_emw_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.189Z"
    }
   },
   "outputs": [],
   "source": [
    "adf(df_log_emw_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking Trends and Seasonality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.195Z"
    }
   },
   "outputs": [],
   "source": [
    "#Take first difference:\n",
    "df_log_diff = df_log - df_log.shift()\n",
    "plt.plot(df_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.198Z"
    }
   },
   "outputs": [],
   "source": [
    "df_log_diff.dropna(inplace=True)\n",
    "test_stats(df_log_diff)\n",
    "adf(df_log_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decomposition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.203Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(df_log, freq=52)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(df_log, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.206Z"
    }
   },
   "outputs": [],
   "source": [
    "df_log_decompose = residual\n",
    "df_log_decompose.dropna(inplace=True)\n",
    "test_stats(df_log_decompose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Starting with Stocker</h1>\n",
    "<h2>Potential Profit</h2>\n",
    "We can then evaluate the potential profit we would have from those shares. You can also change the dates if you feel like trying to lose money! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.212Z"
    }
   },
   "outputs": [],
   "source": [
    "stock.buy_and_hold(start_date=start_date, end_date=end_date, nshares=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Changepoints</h2>\n",
    "\n",
    "One of the most important concepts in a time-series is changepoints. These occur at the maximum value of the second derivative. If that doesn't make much sense, they are times when the series goes from increasing to decreasing or vice versa, or when the series goes from increasing slowly to increasing rapidly. \n",
    "\n",
    "We can easily view the changepoints identified by the Prophet model with the following method. This lists the changepoints and displays them on top of the actual data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.216Z"
    }
   },
   "outputs": [],
   "source": [
    "stock.changepoint_date_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Now that we have analyzed the stock, the next question is where is it going? For that we will have to turn to predictions! \n",
    "That is for another notebook, but here is a little idea of what we can do (check out the documentation on GitHub for full details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.221Z"
    }
   },
   "outputs": [],
   "source": [
    "model, future = stock.create_prophet_model(days=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T09:56:14.224Z"
    }
   },
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
